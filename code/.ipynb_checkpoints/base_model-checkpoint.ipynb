{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from numpy import array\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 将一段话变成向量，组成矩阵输入到模型中处理\n",
    "cv = TfidfVectorizer(binary=False, decode_error='ignore', stop_words='english')\n",
    "# 传入多个句子组成的list\n",
    "vec = cv.fit_transform([\"hello world\", \"this is a panda.\"])\n",
    "vec.toarray()\n",
    "array([[0.70710678, 0.        , 0.70710678],\n",
    "       [0.        , 1.        , 0.        ]])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "data = array([1,2,3,4,5,6])\n",
    "kfold = KFold(n_splits=3, shuffle=True, random_state=1)\n",
    "for train, test in kfold.split(data):\n",
    "    print(\"train: %s, test: %s\" % (data[train], data[test]))\n",
    "    \n",
    "train: [1 4 5 6], test: [2 3]\n",
    "train: [2 3 4 6], test: [1 5]\n",
    "train: [1 2 3 5], test: [4 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "train = pd.read_csv('../data/train.csv', parse_dates=[\"activation_date\"]).sample(10000)\n",
    "test = pd.read_csv('../data/test.csv', parse_dates=[\"activation_date\"]).sample(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindex = train.shape[0]\n",
    "testdex = test.shape[0]\n",
    "train_y = train[\"deal_probability\"]\n",
    "\n",
    "print(\"Train shape: {} Rows, {} Columns\".format(*train.shape))\n",
    "print(\"Test shape: {} Rows, {} Columns\".format(*test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train, test], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "样本对应的特征包括：类别，文本，数值，日期。\n",
    "\n",
    "对于特征的处理主要分为三大块：\n",
    "\n",
    "1. 特征工程\n",
    "\n",
    "2. 文本NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('df.shape: ', df.shape)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1. 价格特征\n",
    "# 对价格进行均值填充\n",
    "df[\"price\"].fillna(np.nanmean(df[\"price\"].values))\n",
    "\n",
    "# 对价格取log后进行填充\n",
    "df[\"price_new\"] = np.log(df[\"price\"].values)\n",
    "df[\"price_new\"].fillna(np.nanmean(df[\"price_new\"].values), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_top_1  -  Avito的图像分类代码。\n",
    "# 采用-999进行填充，决策树会将-999分为一类，而线性模型不可以。\n",
    "df[\"image_top_1\"].fillna(-999, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 时间特征\n",
    "# activation_date 广告上架时间\n",
    "df[\"Weekday\"] = df['activation_date'].dt.weekday\n",
    "df[\"Weekday of Year\"] = df['activation_date'].dt.week\n",
    "df[\"Day of Month\"] = df['activation_date'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 类别特征\n",
    "# 类别特征很多，这里直接将这些类别进行labelencoder；\n",
    "# 由于采用的是基于决策树的lightgbm，所以没有必要进行onehot编码。\n",
    "categorical = [\"user_id\", \"region\", \"city\", \"parent_category_name\", \"category_name\", \"user_type\",\n",
    "               \"image_top_1\", \"param_1\", \"param_2\", \"param_3\"]\n",
    "print(\"Encoding: \", categorical)\n",
    "\n",
    "lbl = preprocessing.LabelEncoder()\n",
    "for col in categorical:\n",
    "    df[col] = lbl.fit_transform(df[col].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 采用lightgbm可以对类别特征做自动填充，对于文本类和数值类的还需要自己做一些填充工作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 文本特征\n",
    "# 采用NA进行填充\n",
    "textfeatures = [\"description\", \"title\"]\n",
    "df[\"description\"].fillna(\"NA\", inplace=True)\n",
    "\n",
    "for col in textfeatures:\n",
    "    df[col] = df[col].astype(str)\n",
    "    df[col] = df[col].astype(str).fillna('missing') \n",
    "    df[col] = df[col].str.lower() # 小写所有文本\n",
    "    df[col + '_num_words'] = df[col].apply(lambda d: len(d.split())) # 文本长度\n",
    "    df[col + '_num_unique_words'] = df[col].apply(lambda d: len(set(w for w in d.split())))\n",
    "    df[col + '_words_vs_unique'] = df[col + '_num_unique_words'] / df[col + '_num_words'] * 100 # 统计独特的单词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFIDF Vectorizer\n",
    "russian_stop = set(stopwords.words('russian'))\n",
    "\n",
    "params = {\n",
    "    \"stop_words\": russian_stop,\n",
    "    \"analyzer\": \"word\",\n",
    "    \"token_pattern\": r'\\w{1,}',\n",
    "    \"norm\": \"l2\",\n",
    "    \"max_features\": 1000,\n",
    "    \"smooth_idf\": False,\n",
    "    \"ngram_range\": (1,1) # n-gram的n-values的下限和上限范围\n",
    "    # 比如'Python is useful'中的ngram_range(1,3)之后可得到'Python'  'is'  'useful'  'Python is'  'is useful' 和'Python is useful'如果是ngram_range (1,1) 则只能得到单个单词'Python'  'is'和'useful'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TSVD的作用是对矩阵进行降维，我们可以指定降维后的主题个数K，这里K指定为10。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_comp = 10\n",
    "for col in textfeatures:\n",
    "    tfidf_vec = TfidfVectorizer(params)\n",
    "    full_tfidf = tfidf_vec.fit_transform(df[col].values.tolist()) # 将文本corpus输入，TF-IDF权重矩阵\n",
    "    svd_obj = TruncatedSVD(n_components=n_comp, algorithm='arpack')\n",
    "    svd_obj.fit(full_tfidf)\n",
    "    full_svd = pd.DataFrame(svd_obj.transform(full_tfidf))\n",
    "    df = pd.concat([df, full_svd], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = [\"item_id\", \"user_id\", \"title\", \"description\",'deal_probability',\"activation_date\", \"image\"]\n",
    "df = df.drop(drop_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = df.loc[:traindex-1, :]\n",
    "test_X = df.loc[traindex:, :]\n",
    "print(train_X.shape)\n",
    "print(test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "kfold = KFold(n_splits=5, shuffle=False, random_state=2019)\n",
    "\n",
    "for t1, t2 in kfold.split(train_X, train_y):\n",
    "    print(t1, t2)\n",
    "\n",
    "[10000 10001 10002 ... 49997 49998 49999] [   0    1    2 ... 9997 9998 9999]\n",
    "[    0     1     2 ... 49997 49998 49999] [10000 10001 10002 ... 19997 19998 19999]\n",
    "[    0     1     2 ... 49997 49998 49999] [20000 20001 20002 ... 29997 29998 29999]\n",
    "[    0     1     2 ... 49997 49998 49999] [30000 30001 30002 ... 39997 39998 39999]\n",
    "[    0     1     2 ... 39997 39998 39999] [40000 40001 40002 ... 49997 49998 49999]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Fold API，n-split就是K值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 调参\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "categorical = [\"region\", \"city\", \"parent_category_name\", \"category_name\", \"user_type\",\n",
    "               \"image_top_1\", \"param_1\", \"param_2\", \"param_3\"]\n",
    "\n",
    "N_Split = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=N_Split, shuffle=False, random_state=2019)\n",
    "\n",
    "score_all = []\n",
    "for n_round in range(3500, 5000, 500): # 不同的循环次数\n",
    "    for learning_rate in [0.01, 0.05, 0.01]: # 不同的学习率\n",
    "        params = {\n",
    "            \"objective\": \"regression\",\n",
    "            \"boosting_type\": \"gbdt\",\n",
    "            \"metric\": \"rmse\",\n",
    "            \"learning_rate\": 0.01,\n",
    "            \n",
    "            \"max_depth\": 7,\n",
    "            \"num_leaves\": 100,\n",
    "            \n",
    "            'max_bin':  255,\n",
    "            \"min_data_in_leaf\": 50,\n",
    "\n",
    "            'feature_fraction': 0.70, # 每颗树训练之前选择70%的特征\n",
    "            'bagging_fraction': 0.70, # 加速训练，处理过拟合\n",
    "            'bagging_freq': 5,\n",
    "\n",
    "            # \"drop_rate\": 0.1,\n",
    "            # \"max_drop\": 50,\n",
    "            \"min_child_samples\": 10,  \n",
    "            \"min_child_weight\": 150,     \n",
    "\n",
    "            'verbose': 1\n",
    "        }\n",
    "        \n",
    "        current_score_tmp_all = []\n",
    "        kf = kfold.split(train_X, train_y)\n",
    "        \n",
    "        for train_index, valid_index in kf:\n",
    "            X_train_x, X_train_y, valid_x, valid_y = train_X.iloc[train_index], train_y.iloc[train_index], train_X.iloc[valid_index], train_y.iloc[valid_index]\n",
    "            train_data = lgb.Dataset(X_train_x, X_train_y, categorical_feature=categorical)\n",
    "            valid_data = lgb.Dataset(valid_x, valid_y, categorical_feature=categorical)\n",
    "            bst = lgb.train(params, \n",
    "                            train_data,\n",
    "                           num_boost_round=n_round,\n",
    "                           valid_sets=valid_data,\n",
    "                           verbose_eval=50, # 迭代多少次打印\n",
    "                           early_stopping_rounds=50 # 有多少次分数没有提高则停止\n",
    "                           )\n",
    "            \n",
    "            print(\"Model Evaluate....\")\n",
    "            pred_y = bst.predict(valid_x)\n",
    "            current_score = np.sqrt(metrics.mean_squared_error(valid_y, pred_y))\n",
    "            current_score_tmp_all.append(current_score)\n",
    "        cur_score = np.sum(current_score_tmp_all) / N_Split\n",
    "        print('RMSE score:', cur_score, '[learnig_rate]', learning_rate,'[n_round]',n_round)\n",
    "        score_all.append([cur_score, learning_rate, n_round])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM\n",
    "\n",
    "1. 支持分类特征\n",
    "\n",
    "使用本地分类特征，LightGBM可以提供良好的精确度，不像简单的one-hot编码，LightGBM可以找到分类特征的最优分割，相对于one-hot编码结果，LightGBM可以提供准确的最优分割。\n",
    "\n",
    "用categorical_feature指定分类特征。\n",
    "\n",
    "对于高基数的分类特征，最好把它转化为数字特征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
